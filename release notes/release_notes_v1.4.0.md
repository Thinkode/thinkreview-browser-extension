# ThinkReview - Version 1.4.0 Release Notes

**Release Date:** November 14, 2025
---

## üéØ What's New

### Local Ollama Integration üñ•Ô∏è

**Complete Privacy & Offline Code Reviews:** ThinkReview now supports local AI code reviews using Ollama! Your code never leaves your machine, giving you complete privacy and the ability to review code offline.

- **üîí Complete Privacy**: Your code never leaves your machine - perfect for sensitive projects
- **üí∞ No API Costs**: Free local inference with no usage limits
- **üåê Offline Capability**: Works without internet connection once Ollama is set up
- **üéØ Multiple Models**: Choose from specialized code review models optimized for different use cases
- **üîß Easy Setup**: One-click script to start Ollama with proper CORS configuration

**Why This Matters:**
For developers working with sensitive code, proprietary projects, or in environments with strict data privacy requirements, local AI reviews provide a secure alternative to cloud-based solutions. You get the same intelligent code analysis without sending your code to external services.

**Supported Models:**
- **codellama** (4GB) - Fast and efficient for general use
- **codellama:13b** (8GB) - Better quality for comprehensive reviews
- **deepseek-coder:6.7b** (4GB) - Excellent code understanding
- **qwen2.5-coder:7b** (5GB) - Strong code analysis
- **starcoder2:15b** (9GB) - Great multi-language support
- **codegemma:7b** (5GB) - Fast and capable

---

## ‚ö° Performance Improvements

### Seamless Provider Switching

- **Instant Switching**: Toggle between Cloud AI (Gemini) and Local Ollama with a single click
- **Smart Fallback**: Clear error messages guide you if Ollama isn't running
- **Connection Testing**: Built-in connection test ensures Ollama is properly configured before use

**Technical Improvements:**
- New `OllamaService` class handles all local AI interactions
- Automatic CORS configuration detection and guidance
- Model discovery and refresh functionality
- Optimized prompt engineering for local models

---

## üîß Additional Improvements

- **Setup Script**: New `start-ollama-with-cors.sh` script automatically configures Ollama for browser extension use
- **Comprehensive Documentation**: Complete setup guide (`OLLAMA_SETUP.md`) with troubleshooting tips
- **Settings UI**: Enhanced popup interface with Ollama configuration section
- **Model Selection**: Dropdown to select from installed Ollama models
- **Connection Status**: Real-time connection testing and status indicators
- **Error Handling**: Improved error messages with actionable suggestions

---

## üìù Usage Tips

1. **Quick Start with Ollama**:
   - Install Ollama from [ollama.ai/download](https://ollama.ai/download)
   - Pull a model: `ollama pull codellama`
   - Run the setup script: `./scripts/start-ollama-with-cors.sh`
   - Configure in extension settings: Select "üñ•Ô∏è Local Ollama" and choose your model

2. **Choosing the Right Model**:
   - Start with **codellama** for fast, general-purpose reviews
   - Use **qwen2.5-coder:7b** for more comprehensive analysis
   - Try **starcoder2:15b** for multi-language projects

3. **Hybrid Approach**:
   - Use Ollama for routine reviews and sensitive code
   - Switch to Cloud AI (Gemini) for complex analysis or when offline isn't needed

4. **Troubleshooting**:
   - If you get a 403 error, make sure Ollama is started with CORS enabled
   - Use the provided script or set `OLLAMA_ORIGINS="chrome-extension://*"` environment variable
   - Check the setup guide for detailed troubleshooting steps

---

## üêõ Bug Fixes

- Improved error handling for Ollama connection failures
- Better validation of Ollama configuration settings
- Fixed model refresh functionality in settings

---

## ‚ö†Ô∏è Breaking Changes

None - This is a fully backward-compatible release. Existing Cloud AI functionality remains unchanged.

---

## üìû Support

Having issues or suggestions? We'd love to hear from you:
- **Bug Reports**: Click the "Report a üêû" button in the review panel
- **Feedback Form**: [Share Your Feedback](https://thinkreview.dev/feedback)
- **Ollama Setup Help**: See [OLLAMA_SETUP.md](https://github.com/Thinkode/thinkreview-browser-extension/blob/main/OLLAMA_SETUP.md) for detailed instructions
- **Rate Us**: Leave a review on the Chrome Web Store

---

**Thank you for using ThinkReview!** üöÄ

*Empowering developers with privacy-first AI code reviews.*

